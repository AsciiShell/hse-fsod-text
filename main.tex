%!TEX TS-program = xelatex
\documentclass[a4paper,14pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\input{data/preambular.tex}
\usepackage[fixlanguage]{babelbib}
\usepackage{lastpage}
\begin{document}

    \input{data/title.tex}

    \section*{\normalsize \hfill Аннотация \hfill}

    ...

    \sloppy
    \newpage

    \section*{\normalsize \hfill Abstract \hfill}

    ...

    \newpage

    \tableofcontents
    \pagebreak

    \section*{Введение}
    \addcontentsline{toc}{section}{\protect\numberline{}Введение}


    \newpage


    \section{Обзор литературы}

    \subsection{Основные понятия}

    Задача детекции объектов (object detection) на изображении включает в себя несколько подзадач:
    \begin{enumerate}
        [1)]
        \itemsep0em
        \item определение прямоугольной области, ограничивающей объект (bounding box, bbox);
        \item классификация выделенной области;
    \end{enumerate}
    В результате работы модели, решающей задачу поиска объектов, получаются области или регионы изображения (object proposals) в которых может находиться объект, а также определена вероятность принадлежности этого объекта к определенному классу.

    Дополнительно могут решаться задачи нахождения ключевых точек объекта и сегментации - отделения объекта от фона, нахождение маски объекта.

    Наиболее популярные датасеты для обучения модели детекции объектов: MS~COCO~\cite{COCO}, LVIS~\cite{LVIS}, Objects365~\cite{Objects365}.

    Эмбеддинг (embedding) -- скрытое векторное представление объекта (текстовых, графические, табличных и аудио данных) фиксированной размерности.

    Карта признаков (feature map) -- векторное представление изображения нефиксированной размерности, где элемент карты содержит информацию о некоторой области изображения.

    NMS (non-maximum suppression)~\cite{neubeck2006efficient} -- алгоритм выделения регионов изображения с максимумом уверенности в классификации.
    В данном алгоритме объединяются регионы, отношение площади пересечения к объединению (IoU) которых больше заданного порога.
    Алгоритм позволяет получить из большого числа похожих или маловероятных регионов изображений один или несколько малопересекающихся регионов.

    Mask R-CNN (Regions With CNNs)~\cite{MaskRCNN} -- двухэтапная нейронная сеть, позволяющая решать задачи детекции объектов и сегментации. В основе сети лежит сверточная нейронная сеть FCN (Fully Convolutional Network), состоящая только из сверточных (convolution) слоев и слоев подвыборки (pooling). Первый модуль RPN (Region Proposal Network) позволяет выделить регионы изображения по карте признаков сверточной нейронной сети. Вторым этапом происходит предсказание bounding box, класса и маски объекта для каждого региона.

    YOLO (You Only Look Once)~\cite{redmon2016you} -- семейство архитектур моделей, позволяющее ускорить решение задачи детекции объектов и получать результаты в режиме реального времени.
    Это одноэтапная нейронная сеть, не использующая модуль для выделения регионов изображения.
    В модели сначала получают карты признаков для изображения с помощью сверточных слоев, далее для каждого элемента карты решаются задачи определения класса объекта и его размеров, центр которого находится в данном элементе карты.
    В модели используется 3 карты признаков различных размеров: каждая последующая получается применением набора сверток к предыдущей.
    Такой подход используется для нахождения объектов разных размеров -- маленьких, средних и больших.

    CLIP (Contrastive Language–Image Pre-training)~\cite{CLIP} -- модель, позволяющая переводить текстовые описания и изображения в единое векторное пространство.
    CLIP предоставляет возможность решать задачу детекции объектов без дообучения для произвольных классов.
    В основе модели лежат Text Encoder и Image Encoder для преобразования текста и изображения в векторные представления, косинусное расстояние между которыми максимизируется для релевантных пар текста и изображения и минимизируется для нерелевантных.

    \subsection{Детекция объектов по произвольному текстовому запросу}

    В статье~\cite{ViLD} предложен метод ViLD - Vision and Language knowledge Distillation, позволяющий находить объекты с произвольным текстовым описанием.
    На этапе обучения рассчитываются текстовые эмбеддинги описаний категорий и эмбеддинги регионов изображения с использованием предобученной модели (модель-учитель).
    Обучается модель детекции объектов Mask R-CNN (модель-ученик), которая дополнительно максимизирует расстояние между эмбеддингом региона предобученной модели-учителя и эмбеддингами региона модели-ученика.
    Таким образом, происходит извлечение знаний (дистилляция) из модели-учителя.
    Во время применения модели-ученика предобученная модель-учитель используется только для получения текстовых эмбеддингов, а эмбеддинги для регионов получается из модели-ученика.
    Итоговые регионы получаются в результате ранжирования оценок, полученных как скалярное произведение текстового эмбеддинга модели-учителя и эмбеддинга региона модели-ученика.

    В качестве модели-учителя в статье используется модель CLIP.
    Модель обучена на датасете LVIS. В работе отмечается, что модель может применяться и к другим датасетам (COCO, Objects365) без дообучения.

    Преимуществом описанного подхода является использование одной модели как для выделения регионов, так и для получения их эмбеддингов, что ускоряет время применения, однако точность при таком подходе понижается.

    Полученную модель предлагается использовать следующим образом: для изображения подавать набор текстовых описаний и отбирать заданное количество регионов с минимальным скалярным произведением.

    К недостаткам предлагаемого подхода можно отнести поиск текстовых описаний только на одном изображении, то есть при отсутствии объектов, релевантных набору текстовых описаний, алгоритм выведет требуемое количество регионов (для нерелевантных текстовых описаний скалярное произведение также может быть высокое).

    \subsection{Простая детекция объектов по нескольким примерам}

    В работе~\cite{wang2020few} авторы предлагают двушаговый алгоритм дообучения моделей для детекции на нескольких примерах.
    Кроме того, предложены метрики качества, оценивающие качество работы модели на популярных или на редких изображениях.
    Авторы используют несколько датасетов -- COCO, LVIS и PASCAL VOC,
    и несколько архитектур моделей -- Faster R-CNN, VGG16, YoloV2, для проверки своих гипотез.
    На первом этапе обучается модель на объектах, классы которых часто встречаются в выборке.
    На следующем этапе предлагается заморозить все веса сети, кроме последнего, и обучать модель на выборке, состоящей из частых и редких объектов в равных пропорциях.
    Такой подход позволил повысить качество работы моделей на несколько пунктов, в зависимости от датасета и модели.

    \subsection{Инженерный подход к разметке изображений}

    В решении~\cite{AnnoMage} реализован подход для полу-автоматизированной разметки датасетов изображений. В предложенном приложении автоматически размечаются области, соответствующие выбранным классам датасета COCO, полученные с помощью загруженной модели.

    В отличие от решения ~\cite{AnnoMage} в курсовой работе предлагается подход с дообучением модели на новой разметке и применением модели для произвольных текстовых запросов.

    \subsection{Цель и задачи исследования}

    Задачи:
    \begin{enumerate}
        [1)]
        \itemsep0em
        \item йцу

    \end{enumerate}

    \subsection{Выводы к главе \thesection}
    \begin{enumerate}
        [1)]
        \itemsep0em
        \item йцу
    \end{enumerate}

    \newpage


    \section{Теоретическая часть}

    \subsection{Выводы к главе \thesection}
    \begin{enumerate}
        [1)]
        \itemsep0em
        \item йцу
    \end{enumerate}

    \newpage


    \section{Практическая часть}

    \subsection{Выводы к главе \thesection}



    \newpage


    \section{Заключение}

    В работе изучена...

    \newpage
    \renewcommand{\refname}{{\normalsize \hfill Список использованных источников \hfill}}
%    \bibliographystyle{unsrt}
    \selectbiblanguage{russian}
    \bibliographystyle{BibTeX-Styles/ugost2008mod}
    \bibliography{main}
    \newpage

\end{document}